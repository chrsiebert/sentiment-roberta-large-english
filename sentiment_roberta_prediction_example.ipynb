{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-roberta-prediction-example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-"
      },
      "source": [
        "# Install the transformers library\n",
        "!pip install datasets transformers==4.28.0\n",
        "!pip install --upgrade accelerate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wC0q6Bxp3or"
      },
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "\n",
        "# Create class for data preparation\n",
        "class SimpleDataset:\n",
        "    def __init__(self, tokenized_texts):\n",
        "        self.tokenized_texts = tokenized_texts\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_texts[\"input_ids\"])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNal9hXp6wm"
      },
      "source": [
        "# Load tokenizer and model, create trainer\n",
        "model_name = \"siebert/sentiment-roberta-large-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer = Trainer(model=model)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEzNB5Up5Yc"
      },
      "source": [
        "# Create list of texts (can be imported from .csv, .xls etc.)\n",
        "pred_texts = ['I like that','That is annoying','This is great!','WouldnÂ´t recommend it.']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8cEaNRjxzLX"
      },
      "source": [
        "# Example: Import data from csv-file stored on Google Drive\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#file_name = \"/content/drive/MyDrive/Colab Notebooks/your-filename.csv\"\n",
        "#text_column = \"text\"\n",
        "\n",
        "#df_pred = pd.read_csv(file_name)\n",
        "#pred_texts = df_pred[text_column].dropna().astype('str').tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLUxGXmp7zF"
      },
      "source": [
        "# Tokenize texts and create prediction data set\n",
        "tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)\n",
        "pred_dataset = SimpleDataset(tokenized_texts)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mjnob3sMCl"
      },
      "source": [
        "# Run predictions\n",
        "predictions = trainer.predict(pred_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3O53RHCsVd7"
      },
      "source": [
        "# Transform predictions to labels\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "labels = pd.Series(preds).map(model.config.id2label)\n",
        "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIONI7ett0q"
      },
      "source": [
        "# Create DataFrame with texts, predictions, labels, and scores\n",
        "df = pd.DataFrame(list(zip(pred_texts,preds,labels,scores)), columns=['text','pred','label','score'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
